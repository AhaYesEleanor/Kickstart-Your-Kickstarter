{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment 3 lines containing \"projects\" in this file to create a dataframe of all scraped pages\n",
    "#projects=pd.DataFrame(columns=['kickstarter_page','funding', 'campaign_dates', 'backers', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up Selenium\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.binary_location = '/usr/bin/google-chrome'\n",
    "\n",
    "chromedriver = \"/bin/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(\"/usr/lib/chromium-browser/chromedriver\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kicktraq archive page numbers 1-8000 are available\n",
    "page_numbers = range(1,2)\n",
    "\n",
    "for page_num in page_numbers:\n",
    "    \n",
    "    #test if file for this page already exists\n",
    "    filename = 'kicktraq_files/kicktraq_page_num' + str(page_num)\n",
    "    if os.path.isfile(filename):\n",
    "        continue\n",
    "    \n",
    "    url = 'https://www.kicktraq.com/archive/?page=' + str(page_num)\n",
    "    print('url is ' + url)\n",
    "    \n",
    "    kickstarter_page = []\n",
    "    funding = []\n",
    "    campaign_dates = []\n",
    "    backers = []\n",
    "    categories = []\n",
    "    \n",
    "    driver.get(url)\n",
    "    \n",
    "    #define condition to wait for: 'next page' button title should be 'go to pagenum+1'\n",
    "    next_button_xpath = '//*[@title=\"go to page {}\"]'.format(str(page_num+1))\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, next_button_xpath)))\n",
    "    \n",
    "    #get html from Selenium into Beautiful Soup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    #select each project from kicktraq archive page\n",
    "    all_projects_on_page = soup.find_all(class_=\"project first odd closed\")\n",
    "    all_projects_on_page = all_projects_on_page + soup.find_all(class_=\"project odd closed\")\n",
    "    all_projects_on_page = all_projects_on_page + soup.find_all(class_=\"project closed\")\n",
    "\n",
    "    for project in all_projects_on_page: \n",
    "        \n",
    "        #if funding info is available, include the project. If not, don't!\n",
    "        funding_info = project.find(class_='project-details').find(text=re.compile('Funding: .\\d*.\\d* of .\\d*.\\d*'))\n",
    "        if funding_info != None:\n",
    "            funding.append(str(funding_info).replace('$',''))\n",
    "\n",
    "            kickstarter_page.append(str(project.find('h2').find('a')['href']))\n",
    "            campaign_dates.append(str(project.find(class_='project-details').find(text=re.compile('Dates: \\w* \\d*\\w* \\-\\> \\w* \\d*\\w* \\(\\d*\\)'))))\n",
    "            backers.append(str(project.find(class_='project-details').find(text=re.compile('Backers: \\d*'))))\n",
    "            categories.append(str(project.find(class_='project-cat').find('a').text))\n",
    "            d = {'kickstarter_page': kickstarter_page,'funding': funding,\n",
    "                 'campaign_dates': campaign_dates, 'backers': backers,\n",
    "                 'category': categories}\n",
    "            page_df = pd.DataFrame(d)\n",
    "    \n",
    "    page_df.to_csv(filename,index=False, encoding='utf-8')\n",
    "    \n",
    "    #projects = pd.concat([projects, page_df])\n",
    "    \n",
    "    #kicktraq's robots.txt requests a 10 second sleep\n",
    "    time.sleep(10)\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('kicktraq_data.pickle', 'wb') as f:\n",
    "#    pickle.dump(projects,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
